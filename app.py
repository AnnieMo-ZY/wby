import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import altair as alt
import time
from datetime import datetime, timedelta, timezone,tzinfo

def count_down(xiaban_min):
    week_dict = {1:'Monday', 2:'Tuesday', 3:'Wednesday', 4:'Thursday', 5:'Friday', 6:'Saturday', 7:'Sunday'}
    # è®¾ç½®ä¸­å›½æ—¶åŒº
    today = datetime.today().astimezone(timezone(timedelta(hours=8)))
    year_month = str(today).split()[0]
    with st.empty():
        st.subheader(f'ä¸‹ç­æ—¶é—´è®¾ç½®ä¸º6ç‚¹{xiaban_min}åˆ†')
    xiaban = datetime.strptime('{} 18:{}:00'.format(year_month,xiaban_min), '%Y-%m-%d %H:%M:%S').astimezone(timezone(timedelta(hours=8)))

    if xiaban > today:
        time_diff = str(xiaban - today)
        st.write(time_diff)
        hour = time_diff.split(':')[0]
        min = time_diff.split(':')[1]
        sec = float(time_diff.split(':')[2])
        # 1-5å·¥ä½œæ—¥
        # 6 7å‘¨æœ«
        weekday = datetime.today().astimezone(timezone(timedelta(hours=8))).weekday()
        if weekday <= 5:
            st.subheader(f'ğŸ“†Date:{week_dict[weekday]}')
            st.subheader('â³ è·ç¦»ä¸‹ç­è¿˜æœ‰:{}å°æ—¶ {}åˆ†é’Ÿ {:.0f}ç§’'.format(hour, min, sec))
        elif weekday > 5:
            st.subheader(f'ğŸ“†Date:{week_dict[weekday]} \nå‘¨æœ«å•¦')
            st.subheader('â³ è·ç¦»ä¸‹ç­è¿˜æœ‰:{}å°æ—¶ {}åˆ†é’Ÿ {:.0f}ç§’'.format(hour, min, sec))
    else:
        st.subheader('ä¸‹ç­å•¦ï¼')

# &æœç´¢é€»è¾‘ éœ€è¦æ‰€ä»¥å…³é”®è¯åŒæ—¶å‡ºç°æ‰è®¡ç®—
def and_algo(post,single):
    count = 0 
    #print(len(single))
    for word  in single:
        #print(word)
        if word in post:
            count+=1
    if count == len(single):
        return 1
    else:
        return 0

#åˆå¹¶æ–‡ä»¶
def merge(df_ls):
    #åˆå¹¶åä¿å­˜åˆ—å
    defined_columns = ["å¹³å°ç±»å‹","identify_id",'åˆ†ç±»',"media_id","media_url","æ ‡é¢˜","å†…å®¹","æ–‡ç« åˆ›å»ºæ—¶é—´"
                   ,"å…³é”®è¯","account_id","æ€§åˆ«","åœ°åŸŸ","è´¦å·åç§°","ç®€ä»‹","è®¤è¯åŸå› ","ä¸»é¡µé“¾æ¥","ç²‰ä¸æ•°","äº§å“çº¿","å¾®é—ªæŠ•"
                  ,"ä¸Šæ¶çŠ¶æ€","è´¦å·åˆ†ç±»","çŸ­è§†é¢‘è½¬å‘æ•°","çŸ­è§†é¢‘è¯„è®ºæ•°","çŸ­è§†é¢‘ç‚¹èµæ•°","æ˜¯å¦å‘½ä¸­"]
    files = []
    for df in df_ls:
        copy_df = df.copy() #ä½¿ç”¨å¤‡ä»½ ä¸åœ¨æºæ•°æ®æ›´æ”¹ å¯é‡å¤è¿è¡Œ
        for col in copy_df.columns:
        #æ›´æ”¹åˆ—å
            if 'æ˜¯å¦å¾®é—ªæŠ•' in col:
                copy_df.rename(columns={"æ˜¯å¦å¾®é—ªæŠ•" : "å¾®é—ªæŠ•"}, inplace = True)
            if 'æ˜¯å¦æ˜¯ç²¾ç¡®æœç´¢' in col:
                copy_df.rename(columns={"æ˜¯å¦æ˜¯ç²¾ç¡®æœç´¢" : "æ˜¯å¦å‘½ä¸­"}, inplace = True) 
            if 'red_id' in col:
                copy_df.rename(columns={"red_id" : "account_id"}, inplace = True)
            if 'è´¦å·ç®€ä»‹' in col:
                copy_df.rename(columns={"è´¦å·ç®€ä»‹" : "ç®€ä»‹"}, inplace = True)
            if 'å¾®åšè¯„è®ºæ•°' in col:
                copy_df.rename(columns={"å¾®åšè¯„è®ºæ•°" : "çŸ­è§†é¢‘è¯„è®ºæ•°",'å¾®åšè½¬å‘æ•°':'çŸ­è§†é¢‘è½¬å‘æ•°' ,'å¾®åšç‚¹èµæ•°':'çŸ­è§†é¢‘ç‚¹èµæ•°' }, inplace = True)
            if 'æ ‡é¢˜å†…å®¹' in col:
                copy_df.rename(columns={'æ ‡é¢˜å†…å®¹':'å†…å®¹' }, inplace = True)
            if 'æ˜¯å¦ä¸Šæ¶' in col:
                copy_df.rename(columns={'æ˜¯å¦ä¸Šæ¶':'ä¸Šæ¶çŠ¶æ€' }, inplace = True)
                
       
        #ä¸å­˜åœ¨çš„åˆ—åè¡¥é½
        for d in defined_columns:
            if d not in list(copy_df.columns):
                copy_df.insert(copy_df.shape[1], column = d, value ='null')
        copy_df = copy_df[defined_columns]
        files.append(copy_df)
    final = pd.concat([pd.DataFrame(i) for i in files])
    return final

#å®šä¹‰åŠŸèƒ½

@st.cache
def convert_df(df):
    # IMPORTANT: Cache the conversion to prevent computation on every rerun
    return df.to_csv(encoding = 'utf_8_sig', line_terminator="\n", index = False).encode('utf_8_sig')

# é€‰æ‹©æœç´¢èŒƒå›´
def select_data(dataframe,keyword,platform): #dataframe , keyword:str, platform:str
    if platform == 'All':
        pass
    else:
        dataframe = dataframe[dataframe['å¹³å°ç±»å‹'].isin([platform])]

    dataframe = dataframe[dataframe['å…³é”®è¯'].isin([keyword])]
    return dataframe.reset_index()

# æƒ…æ„Ÿåˆ†ææ¨¡å—
# def emotion_check(post):
#     snownlp = SnowNLP(post)
#     sentiments_score = snownlp.sentiments
#     return sentiments_score

# æœç´¢é€»è¾‘æ¨¡å—
def main(user_input, dataframe):
    content  = dataframe
    posts_length = content.shape[0]
    word_list = user_input.strip().split(',')
    ls1 = [] # ä¿å­˜å«æœ‰ / çš„è¯ 
    ls2 = [] # ä¿å­˜å«æœ‰ & å’Œå…¶ä»–è¯
    for word in word_list:
        if '/' in word:
            ls1.append(word)
        else:
            ls2.append(word)
    d={}

    # FORå¾ªç¯ éå†word_listçš„è¯
    for mulitiple_word in ls1:
        d.update({mulitiple_word:0})
        #æŠŠæœ‰/æ‹†åˆ†
        single = mulitiple_word.split('/')
        #åˆ›å»ºè¾…åŠ©åˆ— =0
        content.loc[:,'è¾…åŠ©åˆ—']= 0
        #éå†æ¯ä¸ªæ‹†åˆ†åçš„è¯
        for word in single: 
            marker_length = 0
            #æ›´æ”¹ æœç´¢åˆ—  ex:æ ‡é¢˜+å†…å®¹
            #éå†æ¯ä¸ª æ ‡é¢˜+å†…å®¹åˆ—
            for post in content['æ ‡é¢˜+å†…å®¹']:  # æ›´æ”¹excelè¡¨æ ¼å¯¹åº”åˆ—å
                #å¦‚æœå«æœ‰å…³é”®è¯ å¹¶è¾…åŠ©åˆ—=0
                try:
                    if word in post  and content['è¾…åŠ©åˆ—'][marker_length] == 0 :
                        #è¾…åŠ©åˆ—æ ‡è®°ä¸º1
                        content['è¾…åŠ©åˆ—'][marker_length] = 1
                    marker_length+=1
                except:
                    print(f'è¯·æ£€æŸ¥excelè¡¨æ ¼å•å…ƒæ ¼: {marker_length}è¡Œ')
                    continue
            #å–æ ‡è®°ä¸º1çš„sum
            count = content['è¾…åŠ©åˆ—'].sum()
        d[mulitiple_word]  = count
        #print(f'å…³é”®è¯:{mulitiple_word} \t æ•°é‡ï¼š{count} \t å æ¯”: {(count/posts_length) * 100 :.2f}%')

    #AND é€»è¾‘
    for mulitiple_word in ls2:
        #æŠŠæœ‰&æ‹†åˆ†
        single = mulitiple_word.split('&')
        #éå†æ¯ä¸ªæ‹†åˆ†åçš„è¯
        word_count = 0
        #temp å‚¨å­˜ and_algoç»“æœ
        temp = []
        for post in content['æ ‡é¢˜+å†…å®¹']: 
            aa = and_algo(post, single)
            temp.append(aa)
            word_count = sum(temp) 
        d[mulitiple_word]  = word_count


    sorted_d = dict(sorted(d.items(), key=lambda x: x[1],reverse =False))
    df = pd.DataFrame(list(sorted_d.items()) ,columns=['å…³é”®è¯','å‘æ–‡æ•°é‡'])
    df.loc[:,'å æ¯”%'] =df['å‘æ–‡æ•°é‡'] /posts_length * 100 
    #å æ¯” ä¿ç•™ 1ä½å°æ•° %
    df.round({'å æ¯”%' : 1})

    #æ•°æ® x,yè½´
    x = list(sorted_d.keys())
    y = list(sorted_d.values())

    return x , y, df

st.title('ğŸŒExcelå°å·¥å…·')
    
uploaded_file = st.file_uploader(label="ä¸Šä¼ Excelæ–‡ä»¶" , type = ['csv','xlsx'],accept_multiple_files=True )
time.sleep(1)
#åˆå¹¶æ–‡ä»¶
if len(uploaded_file) > 1:
    time.sleep(1)
    df_ls = []
    for index, item  in enumerate(uploaded_file):
        if str(item.name).split('.')[1] == 'csv':
            df = pd.read_csv(uploaded_file[index], encoding = 'utf-8') #encoding='gb18030'
            st.write('csvè¯»å–æˆåŠŸ')
            df_ls.append(df)
        elif str(item.name).split('.')[1] == 'xlsx':
            df = pd.read_excel(uploaded_file[index])
            st.write('xlsxè¯»å–æˆåŠŸ')
            df_ls.append(df)
        st.write(f'å…±{len(df_ls)}ä»½æ–‡ä»¶')
            
     
    try:
        concat_data = merge(df_ls)
        concat_data.fillna({'ç²‰ä¸æ•°':0},inplace =True)
        concat_data.fillna('null',inplace =True)
        
    except Exception as e:
        st.write('æ£€æŸ¥åˆ—å')
        st.write(str(e))
    csv = convert_df(concat_data)

    st.download_button(
        label="ä¸‹è½½åˆå¹¶æ–‡ä»¶ as CSV",
        data=csv,
        file_name='combined_file.csv',
        mime = 'text/csv')


col1 , col2, col3 = st.columns(3)
if len(uploaded_file) == 1:
    if str(uploaded_file[0].type).split('/')[1] =='csv':
        dataframe = pd.read_csv(uploaded_file[0])
    else:
        dataframe = pd.read_excel(uploaded_file[0],dtype = str,index_col = False)

    selected_keyword = list(dataframe['å…³é”®è¯'].unique())
    selected_platform = list(dataframe['å¹³å°ç±»å‹'].unique())
    selected_platform.extend(['All'])
    with st.container():
        with col1:
            pltf = st.selectbox('é€‰æ‹©å¹³å°', selected_platform)
        with col2:
            keyword = st.selectbox( 'é€‰æ‹©å…³é”®è¯', selected_keyword)
    dataframe = select_data(dataframe,keyword,pltf)
    st.write('å·²é€‰æ‹©:', pltf,keyword)
    st.write('æ•°æ®è¡¨')
    st.dataframe(dataframe,1000,100)
    user_input = st.text_input('è¾“å…¥æœç´¢å…³é”®è¯', '')
# ç»“æœ
    if user_input:
        try:
            x,y,df =main(user_input,dataframe)

        except:
            st.write('è¯·æ£€æŸ¥Excelè¡¨æ ¼åˆ—å')

        main_result_jason = {'å…³é”®è¯': x, 'æ•°é‡':[int(i) for i in y]}

        df= pd.DataFrame(main_result_jason)
        bars = alt.Chart(df).mark_bar().encode(
            y=alt.Y('å…³é”®è¯',sort = '-x'),
            x=alt.X('æ•°é‡:Q' )).properties( height = 400)

        st.altair_chart(bars, use_container_width=True)
        st.dataframe(df)

with st.sidebar:
    st.subheader('ğŸŒŸä½¿ç”¨æ­¥éª¤')
    st.write('1: ä¼ å…¥Excel xlsx,csvæ ¼å¼ é»˜è®¤è¯»å–ç¬¬ä¸€å¼ sheet')
    st.write('2: é€‰ä¸­å¯¹åº”å¹³å°ç±»å‹ + å…³é”®è¯')
    st.write('3: æ–‡æœ¬æ¡†è¾“å…¥æœç´¢è¯')
    st.write('å¤‡æ³¨: ä¸Šä¼ å¤šæ–‡ä»¶è‡ªåŠ¨åˆå¹¶æ–‡ä»¶')
    xiaban_min = st.slider('ä¸‹ç­æ—¶é—´ä¸º6ç‚¹ ',0,60, step=1)

    count_down(xiaban_min)

        #st.subheader("âœ”ï¸ one minute passed!")
